**2019.10.10**
<!-- MarkdownTOC -->

- [一 JDK 提供的并发容器总结](#一-jdk-提供的并发容器总结)
- [二 ConcurrentHashMap](#二-concurrenthashmap)
- [三 CopyOnWriteArrayList](#三-copyonwritearraylist)
  - [3.1 CopyOnWriteArrayList 简介](#31-copyonwritearraylist-简介)
  - [3.2 CopyOnWriteArrayList 是如何做到的？](#32-copyonwritearraylist-是如何做到的？)
  - [3.3 CopyOnWriteArrayList 读取和写入源码简单分析](#33-copyonwritearraylist-读取和写入源码简单分析)
    - [3.3.1 CopyOnWriteArrayList 读取操作的实现](#331-copyonwritearraylist-读取操作的实现)
    - [3.3.2 CopyOnWriteArrayList 写入操作的实现](#332-copyonwritearraylist-写入操作的实现)
- [四 ConcurrentLinkedQueue](#四-concurrentlinkedqueue)
- [五 BlockingQueue](#五-blockingqueue)
  - [5.1 BlockingQueue 简单介绍](#51-blockingqueue-简单介绍)
  - [5.2 ArrayBlockingQueue](#52-arrayblockingqueue)
  - [5.3 LinkedBlockingQueue](#53-linkedblockingqueue)
  - [5.4 PriorityBlockingQueue](#54-priorityblockingqueue)
- [六 参考](#六-参考)

<!-- /MarkdownTOC -->
# 深入锁和并发的核心——并发集合（2）
##  一 JDK 提供的并发容器总结

JDK提供的这些容器大部分在  java.util.concurrent包中。

- **ConcurrentHashMap:** 线程安全的HashMap，1.7和1.8的分段加锁机制不同
- **CopyOnWriteArrayList:** 线程安全的List，在读多写少的场合性能非常好，远远好于Vector.，读写分离
- **ConcurrentLinkedQueue:** 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。全部使用CAS实现，效率非常高
- **BlockingQueue:** 这是一个接口，JDK内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。类似于消息队列，实现此接口的类包括Arrayblockingqueue和linkedblockingqueue（名字是真心长）和其他一些，适配生产消费者问题。


## 二 ConcurrentHashMap

我们知道 HashMap 不是线程安全的，在并发场景下如果要保证一种可行的方式是使用 `Collections.synchronizedMap()`（是一把大锁，不合适） 方法来包装我们的 HashMap。但这是通过使用一个全局的锁来同步不同线程间的并发访问，因此会带来不可忽视的性能问题。

所以就有了 HashMap 的线程安全版本—— ConcurrentHashMap 的诞生。在ConcurrentHashMap中，无论是读操作还是写操作都能保证很高的性能：在进行读操作时(几乎)不需要加锁，而在写操作时通过锁分段技术只对所操作的段加锁而不影响客户端对其它段的访问。

### ConcurrentHashMap和Hashtable以及Hashmap
关于Hashmap的实现，在之前的文章中已经介绍过了其底层的实现，数组链表的数据结构和扩容的机制。
#### Hashtable
![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jYW1vLmdpdGh1YnVzZXJjb250ZW50LmNvbS82MDkyMDk2OGMwZTE5ODc4Y2EyYTNhMTUzY2JlNDg3MmY5NTBiNTcxLzY4NzQ3NDcwNzMzYTJmMmY2ZDc5MmQ2MjZjNmY2NzJkNzQ2ZjJkNzU3MzY1MmU2ZjczNzMyZDYzNmUyZDYyNjU2OTZhNjk2ZTY3MmU2MTZjNjk3OTc1NmU2MzczMmU2MzZmNmQyZjMyMzAzMTM5MmQzNjJmNDg2MTczNjg1NDYxNjI2YzY1MjU0NTM1MjUzODM1MjU0MTM4MjU0NTM4MjU0MTMxMjU0MTM4MjU0NTM5MjUzOTM0MjUzODMxMmU3MDZlNjc?x-oss-process=image/format,png) 如上面的介绍图，在整个hashtable的内部的实现是在其每个方法前面加上synchronized修饰，相当于对整个表上锁，当一个get或者put方法时，整个表阻塞，禁止其他方法访问，效率低下，其他是不能放置NULL等差异。
#### ConcurrentHashmap
1.7：在JDK1.7的时候，对其的实现是数组（Segment）+数组(Node桶数组)+链表的形式..整个Hashmap由外层的Segment数组构成，容量为16。每个Segment元素是一个和原来HashMap 相似的数据结构。其作为并发容器的实现是对每一个Segment上锁，即分段锁。这样可以同时访问不同段位置的元素，提高了并发时候的运行效率。
![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jYW1vLmdpdGh1YnVzZXJjb250ZW50LmNvbS8wOTJhYWUxNmMzYTM4ODU0YjRjZWE4YjdlNDJkYzY3MjBkZjQ0NDFmLzY4NzQ3NDcwNzMzYTJmMmY2ZDc5MmQ2MjZjNmY2NzJkNzQ2ZjJkNzU3MzY1MmU2ZjczNzMyZDYzNmUyZDYyNjU2OTZhNjk2ZTY3MmU2MTZjNjk3OTc1NmU2MzczMmU2MzZmNmQyZjMyMzAzMTM5MmQzNjJmNDM2ZjZlNjM3NTcyNzI2NTZlNzQ0ODYxNzM2ODRkNjE3MDI1NDUzNTI1MzgzODI1MzgzNjI1NDUzNjI1NDE0NTI1NDIzNTI1NDUzOTI1MzkzNDI1MzgzMTJlNmE3MDY3?x-oss-process=image/format,png)

1.8：在JDK1.8的时候，取消了Segment分段锁，采用CAS和synchronized来保证并发安全。数据结构跟HashMap1.8的结构类似，数组+链表/红黑二叉树。synchronized只锁定当前链表或红黑二叉树的首节点，这样只要hash不冲突，就不会产生并发，效率又提升N倍。
有几点知识：

![在这里插入图片描述](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jYW1vLmdpdGh1YnVzZXJjb250ZW50LmNvbS9iODIzYzVmMmNmMThlN2UyN2RhNzA0MDlkMmI1ZTE4ZmVkODIwMzY0LzY4NzQ3NDcwNzMzYTJmMmY2ZDc5MmQ2MjZjNmY2NzJkNzQ2ZjJkNzU3MzY1MmU2ZjczNzMyZDYzNmUyZDYyNjU2OTZhNjk2ZTY3MmU2MTZjNjk3OTc1NmU2MzczMmU2MzZmNmQyZjMyMzAzMTM5MmQzNjJmNGE0NDRiMzEyZTM4MmQ0MzZmNmU2Mzc1NzI3MjY1NmU3NDQ4NjE3MzY4NGQ2MTcwMmQ1Mzc0NzI3NTYzNzQ3NTcyNjUyZTZhNzA2Nw?x-oss-process=image/format,png)


CAS和synchronized：ConcurrentHashmap使用CAS操作来插入桶数组的头节点node，防止同时创建两个需要加锁的节点，借助一个循环进行判断，如果插入失败，说明已经有别的线程插入头结点了，再次循环进行操作。如果头结点已经存在，则通过synchronized获得头结点锁，进行后续的操作。性能比segment分段锁又再次提升。

**为啥使用synchronized而不是lock:：因为synchronized在1.8后有三种状态，其偏向状态和轻量级状态是不需要进行线程切换的，如果使用lock的换需要每次加锁解锁的开销，不划算。**

#####  ConcurrentHashMap的扩容机制也和原来的不一样
在1.7的ConcurrentHashMap中是每个Segment进行扩容，而在1.8后也是对一张表进行扩容，考虑到多线程的环境，其扩容的机制显得十分的巧妙。有以下几个参数。

**sizeCtl** 设置成volatile的属性，来判断当前Map是否在扩容，如果<0表示在扩容，如果=0.75n表示扩容阈值。

**ForwardingNode**在扩容的过程中有一个ForwardingNode的内部类的节点起到标记作用，表示其他节点还在扩容，此节点已经扩容完毕，但其管理了nextTable,即可通过find访问，访问到已经迁移到新MAP的节点。

**tranferindex** 表示还有多少个node节点还没扩容完毕，每次来线程帮忙扩容后就减少，像put这样的线程进来后反正操作不了，就帮助扩容，进行迁移，每个线程帮助16个扩容，即来一个线程 tranferindex-16.


## 三 CopyOnWriteArrayList

### 3.1 CopyOnWriteArrayList 简介

```java
public class CopyOnWriteArrayList<E>extends Object
implements List<E>, RandomAccess, Cloneable, Serializable
```
（注意这里没有继承自AbstrctList,只是实现了List的接口，没有modcount，不会出现快速失败，再说其内部的iteritor都是用静态内部类实现的ListIterator，其中的add和remove 方法都没实现，会抛Unsupport异常）

在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，因此对于每次读取都进行加锁其实是一种资源浪费。我们应该允许多个线程同时访问List的内部数据，毕竟读取操作是安全的。

这和我们之前在多线程章节讲过 `ReentrantReadWriteLock` 读写锁的思想非常类似，也就是读读共享、写写互斥、读写互斥、写读互斥。JDK中提供了 `CopyOnWriteArrayList` 类比相比于在读写锁的思想又更进一步。为了将读取的性能发挥到极致，`CopyOnWriteArrayList` 读取是完全不用加锁的，并且更厉害的是：写入也不会阻塞读取操作。只有写入和写入之间需要进行同步等待。这样一来，读操作的性能就会大幅度提升。**那它是怎么做的呢？**

### 3.2 CopyOnWriteArrayList 是如何做到的？

 `CopyOnWriteArrayList` 类的所有可变操作（add，set等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

从 `CopyOnWriteArrayList` 的名字就能看出`CopyOnWriteArrayList` 是满足`CopyOnWrite` 的ArrayList，所谓`CopyOnWrite` 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。

**值得注意的一点是：这种数据结构能保证数据的最终一致性，保证不了数据的实时一致性。如果一个一个正在写，还没写完，其他的来读了，就要读到原来的，不能保证保证实时一致性，保证实时一致性需要加锁，以牺牲性能为代价的。**
### 3.3 CopyOnWriteArrayList 读取和写入源码简单分析

#### 3.3.1 CopyOnWriteArrayList 读取操作的实现

读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。

```java
    /** The array, accessed only via getArray/setArray. */
    private transient volatile Object[] array;
    public E get(int index) {
        return get(getArray(), index);
    }
    @SuppressWarnings("unchecked")
    private E get(Object[] a, int index) {
        return (E) a[index];
    }
    final Object[] getArray() {
        return array;
    }

```

#### 3.3.2 CopyOnWriteArrayList 写入操作的实现

CopyOnWriteArrayList 写入操作 add() 方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。

```java
    /**
     * Appends the specified element to the end of this list.
     *
     * @param e element to be appended to this list
     * @return {@code true} (as specified by {@link Collection#add})
     */
    public boolean add(E e) {
        final ReentrantLock lock = this.lock;
        lock.lock();//加锁
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);//拷贝新数组
            newElements[len] = e;
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();//释放锁
        }
    }
```

## 四 ConcurrentLinkedQueue
在并发的队列容器之中，有以下方法要注意区别开：
**offer(队列满的时候会返回false)(返回值boolean)**
**put(在队列满的时候阻塞)（返回值是void）并发队列独有**
**take(在队列空的时候阻塞) 同样是独有**
**在阻塞的时候使用的是并发包中的Condition，和锁绑定，一种信号机制（如下）。通过await阻塞和signal唤醒（从等待队列中拿出一个线程执行），在锁构造的AQS中实现。**

```
Condition   notEmpty = lock.newCondition();
Condition   notFull =  lock.newCondition();
```

Java提供的线程安全的 Queue 可以分为**阻塞队列**和**非阻塞队列**，其中阻塞队列的典型例子是 BlockingQueue，非阻塞队列的典型例子是ConcurrentLinkedQueue，在实际应用中要根据实际需要选用阻塞队列或者非阻塞队列。 **阻塞队列可以通过加锁来实现，非阻塞队列可以通过 CAS 操作实现。**

从名字可以看出，`ConcurrentLinkedQueue`这个队列使用链表作为其数据结构．ConcurrentLinkedQueue 应该算是在高并发环境中性能最好的队列了。它之所有能有很好的性能，是因为其内部复杂的实现。

ConcurrentLinkedQueue 内部代码我们就不分析了，大家知道ConcurrentLinkedQueue 主要使用 **CAS 非阻塞**算法来实现线程安全就好了。

ConcurrentLinkedQueue 适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的ConcurrentLinkedQueue来替代。

##  五 BlockingQueue

### 5.1 BlockingQueue 简单介绍

上面我们己经提到了 ConcurrentLinkedQueue 作为高性能的非阻塞队列。下面我们要讲到的是阻塞队列——BlockingQueue。阻塞队列（BlockingQueue）被广泛使用在“生产者-消费者”问题中，其原因是BlockingQueue提供了可阻塞的插入和移除的方法。当队列容器已满，生产者线程会被阻塞，直到队列未满；当队列容器为空时，消费者线程会被阻塞，直至队列非空时为止。

BlockingQueue 是一个接口，继承自 Queue，所以其实现类也可以作为 Queue 的实现来使用，而 Queue 又继承自 Collection 接口。下面是 BlockingQueue 的相关实现类：

![BlockingQueue 的实现类](https://imgconvert.csdnimg.cn/aHR0cDovL215LWJsb2ctdG8tdXNlLm9zcy1jbi1iZWlqaW5nLmFsaXl1bmNzLmNvbS8xOC0xMi05LzUxNjIyMjY4LmpwZw?x-oss-process=image/format,png)

**下面主要介绍一下:ArrayBlockingQueue、LinkedBlockingQueue、PriorityBlockingQueue，这三个 BlockingQueue 的实现类。**

### 5.2 ArrayBlockingQueue

**ArrayBlockingQueue** 是 BlockingQueue 接口的有界队列实现类，底层采用**数组**来实现。ArrayBlockingQueue一旦创建，容量不能改变。其并发控制采用可重入锁来控制，不管是插入操作还是读取操作，都需要获取到锁才能进行操作。当队列容量满时，尝试将元素放入队列将导致操作阻塞;尝试从一个空队列中取一个元素也会同样阻塞。

ArrayBlockingQueue 默认情况下不能保证线程访问队列的公平性，所谓公平性是指严格按照线程等待的绝对时间顺序，即最先等待的线程能够最先访问到 ArrayBlockingQueue。而非公平性则是指访问 ArrayBlockingQueue 的顺序不是遵守严格的时间顺序，有可能存在，当 ArrayBlockingQueue 可以被访问时，长时间阻塞的线程依然无法访问到 ArrayBlockingQueue。如果保证公平性，通常会降低吞吐量。如果需要获得公平性的 ArrayBlockingQueue，这里的公平非公平的实现机制和之前文章的公平锁非公平锁一致，是刚进来的线程可能抢占锁导致饥饿现象的发生。这里的不公平是指线程等待时间不公平，对于只要进入队列的内部消息来说依然是FIFO的。

可采用如下代码：

```java
private static ArrayBlockingQueue<Integer> blockingQueue = new ArrayBlockingQueue<Integer>(10,true);
```

### 5.3 LinkedBlockingQueue

**LinkedBlockingQueue** 底层基于**单向链表**实现的阻塞队列，可以当做无界队列也可以当做有界队列来使用，同样满足FIFO的特性，与ArrayBlockingQueue 相比起来具有更高的吞吐量，为了防止 LinkedBlockingQueue 容量迅速增，损耗大量内存。通常在创建LinkedBlockingQueue 对象时，会指定其大小，如果未指定，容量等于Integer.MAX_VALUE。

对比于ArrayBlockingQueue,其具备两把锁，put操作的锁和take操作的锁，这样两种生产消费操作不阻塞，具备更高的效率。可指定大小，可有界，可无界。

**相关构造方法:**

```java
    /**
     *某种意义上的无界队列
     * Creates a {@code LinkedBlockingQueue} with a capacity of
     * {@link Integer#MAX_VALUE}.
     */
    public LinkedBlockingQueue() {
        this(Integer.MAX_VALUE);
    }

    /**
     *有界队列
     * Creates a {@code LinkedBlockingQueue} with the given (fixed) capacity.
     *
     * @param capacity the capacity of this queue
     * @throws IllegalArgumentException if {@code capacity} is not greater
     *         than zero
     */
    public LinkedBlockingQueue(int capacity) {
        if (capacity <= 0) throw new IllegalArgumentException();
        this.capacity = capacity;
        last = head = new Node<E>(null);
    }
```

## 六 参考
### [并发容器总结](https://github.com/Snailclimb/JavaGuide/blob/master/docs/java/Multithread/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E6%80%BB%E7%BB%93.md#53-linkedblockingqueue)



